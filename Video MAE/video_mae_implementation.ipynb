{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","machine_shape":"hm","collapsed_sections":["-Sk2REFBjcru"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Downloads"],"metadata":{"id":"8TzfMEYdtDrz"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"b8PYl528Z2Wq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711922858673,"user_tz":240,"elapsed":4427,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"e601f490-4084-4757-eaac-8bd356917214"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into '/content/mae_temp'...\n","remote: Enumerating objects: 133, done.\u001b[K\n","remote: Counting objects: 100% (47/47), done.\u001b[K\n","remote: Compressing objects: 100% (31/31), done.\u001b[K\n","remote: Total 133 (delta 26), reused 18 (delta 16), pack-reused 86\u001b[K\n","Receiving objects: 100% (133/133), 990.61 KiB | 3.09 MiB/s, done.\n","Resolving deltas: 100% (63/63), done.\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["!mkdir /content/mae_temp\n","!git clone https://github.com/OpenGVLab/VideoMAEv2 /content/mae_temp\n","!cp -rn /content/mae_temp/* /content/\n","!rm -rf /content/mae_temp\n","\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install av\n","!pip install decord\n","!pip install deepspeed\n","!pip install einops\n","!pip install matplotlib\n","!pip install mpi4py\n","!pip install numpy\n","!pip install opencv-python\n","!pip install pandas\n","!pip install Pillow\n","!pip install scipy\n","!pip install tensorboard==2.9.0\n","!pip install tensorboardX==1.8\n","!pip install timm==0.4.12\n","!pip install torch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1\n","!pip install triton==1.0.0\n","!pip install utils"],"metadata":{"id":"MtaewJOAlana","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708386812867,"user_tz":300,"elapsed":202407,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"61d18f17-0590-4ae9-b688-76ad945494bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting av\n","  Downloading av-11.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: av\n","Successfully installed av-11.0.0\n","Collecting decord\n","  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from decord) (1.25.2)\n","Installing collected packages: decord\n","Successfully installed decord-0.6.0\n","Collecting deepspeed\n","  Downloading deepspeed-0.13.2.tar.gz (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting hjson (from deepspeed)\n","  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ninja (from deepspeed)\n","  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.6.1)\n","Collecting pynvml (from deepspeed)\n","  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.1.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (2.16.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (4.9.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n","Building wheels for collected packages: deepspeed\n","  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for deepspeed: filename=deepspeed-0.13.2-py3-none-any.whl size=1360173 sha256=c108e5f8424e6a9bc978b92648d0bdc7ae5400f8ee8ac42e09e2d9de763543b7\n","  Stored in directory: /root/.cache/pip/wheels/a8/78/a8/62089b9f05586da0176ff0c959bdb756c57f9d44a4fa63d2a6\n","Successfully built deepspeed\n","Installing collected packages: ninja, hjson, pynvml, deepspeed\n","Successfully installed deepspeed-0.13.2 hjson-3.1.0 ninja-1.11.1.1 pynvml-11.5.0\n","Collecting einops\n","  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.7.0\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.48.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Collecting mpi4py\n","  Downloading mpi4py-3.1.5.tar.gz (2.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: mpi4py\n","  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for mpi4py: filename=mpi4py-3.1.5-cp310-cp310-linux_x86_64.whl size=2746512 sha256=5e59d5ac76f98108a69a5f7962d9e160cf5b2a280ef816b0c32e21b10c42ec0a\n","  Stored in directory: /root/.cache/pip/wheels/18/2b/7f/c852523089e9182b45fca50ff56f49a51eeb6284fd25a66713\n","Successfully built mpi4py\n","Installing collected packages: mpi4py\n","Successfully installed mpi4py-3.1.5\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n","Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n","Collecting tensorboard==2.9.0\n","  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (1.4.0)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (1.60.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (2.27.0)\n","Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard==2.9.0)\n","  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (3.5.2)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (1.25.2)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (2.31.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (67.7.2)\n","Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard==2.9.0)\n","  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard==2.9.0)\n","  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (3.0.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard==2.9.0) (0.42.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.0) (5.3.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.0) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard==2.9.0) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.0) (1.3.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard==2.9.0) (2024.2.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard==2.9.0) (2.1.5)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.9.0) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.9.0) (3.2.2)\n","Installing collected packages: tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, tensorboard\n","  Attempting uninstall: tensorboard-data-server\n","    Found existing installation: tensorboard-data-server 0.7.2\n","    Uninstalling tensorboard-data-server-0.7.2:\n","      Successfully uninstalled tensorboard-data-server-0.7.2\n","  Attempting uninstall: google-auth-oauthlib\n","    Found existing installation: google-auth-oauthlib 1.2.0\n","    Uninstalling google-auth-oauthlib-1.2.0:\n","      Successfully uninstalled google-auth-oauthlib-1.2.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.15.2\n","    Uninstalling tensorboard-2.15.2:\n","      Successfully uninstalled tensorboard-2.15.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","pandas-gbq 0.19.2 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n","tensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\n","Collecting tensorboardX==1.8\n","  Downloading tensorboardX-1.8-py2.py3-none-any.whl (216 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.3/216.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX==1.8) (1.25.2)\n","Requirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorboardX==1.8) (3.20.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorboardX==1.8) (1.16.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-1.8\n","Collecting timm==0.4.12\n","  Downloading timm-0.4.12-py3-none-any.whl (376 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (2.1.0+cu121)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.4.12) (0.16.0+cu121)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (4.9.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (3.1.3)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->timm==0.4.12) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.4.12) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->timm==0.4.12) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->timm==0.4.12) (2024.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4->timm==0.4.12) (1.3.0)\n","Installing collected packages: timm\n","Successfully installed timm-0.4.12\n","Collecting torch==1.12.1\n","  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchvision==0.13.1\n","  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torchaudio==0.12.1\n","  Downloading torchaudio-0.12.1-cp310-cp310-manylinux1_x86_64.whl (3.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1) (4.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (1.25.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (9.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2024.2.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.1.0+cu121\n","    Uninstalling torch-2.1.0+cu121:\n","      Successfully uninstalled torch-2.1.0+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.16.0+cu121\n","    Uninstalling torchvision-0.16.0+cu121:\n","      Successfully uninstalled torchvision-0.16.0+cu121\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.1.0+cu121\n","    Uninstalling torchaudio-2.1.0+cu121:\n","      Successfully uninstalled torchaudio-2.1.0+cu121\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n","torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed torch-1.12.1 torchaudio-0.12.1 torchvision-0.13.1\n","\u001b[31mERROR: Could not find a version that satisfies the requirement triton==1.0.0 (from versions: 2.0.0.dev20221030, 2.0.0.dev20221031, 2.0.0.dev20221101, 2.0.0.dev20221103, 2.0.0.dev20221105, 2.0.0.dev20221117, 2.0.0.dev20221120, 2.0.0.dev20221202, 2.0.0.dev20230208, 2.0.0.dev20230217, 2.0.0a1, 2.0.0a2, 2.0.0, 2.0.0.post1, 2.1.0, 2.2.0)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for triton==1.0.0\u001b[0m\u001b[31m\n","\u001b[0mCollecting utils\n","  Downloading utils-1.0.2.tar.gz (13 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: utils\n","  Building wheel for utils (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13905 sha256=726594bcc990541a28991aa4c068c9e7ec62c53f83aecbfc70859dbfb3e72eaf\n","  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n","Successfully built utils\n","Installing collected packages: utils\n","Successfully installed utils-1.0.2\n"]}]},{"cell_type":"markdown","source":["#Finetuning"],"metadata":{"id":"-Sk2REFBjcru"}},{"cell_type":"code","source":["!unzip -u \"/content/drive/My Drive/k710_list.zip\" -d \"/content/data\"\n","DATA_PATH = \"/content/data/k710\"\n","\n","MODEL_PATH = '/content/drive/MyDrive/vit_g_hybrid_pt_1200e_k710_ft.pth'\n","\n","!mkdir \"/content/output\"\n","OUTPUT_DIR = \"content/output\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j8pJVNnHoKbM","executionInfo":{"status":"ok","timestamp":1705366911522,"user_tz":300,"elapsed":313,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"1aaf8ebb-874f-49d4-b619-4db521f7a7c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/My Drive/k710_list.zip\n","mkdir: cannot create directory ‘/content/output’: File exists\n"]}]},{"cell_type":"code","source":["from argparse import Namespace\n","\n","!python run_class_finetuning.py \\\n","    --model vit_giant_patch14_224 \\\n","    --data_set Kinetics-710 \\\n","    --nb_classes 710 \\\n","    --data_path $DATA_PATH \\\n","    --finetune $MODEL_PATH \\\n","    --log_dir $OUTPUT_DIR \\\n","    --output_dir $OUTPUT_DIR \\\n","    --batch_size 3 \\\n","    --input_size 224 \\\n","    --short_side_size 224 \\\n","    --save_ckpt_freq 10 \\\n","    --num_frames 16 \\\n","    --sampling_rate 4 \\\n","    --num_sample 2 \\\n","    --num_workers 10 \\\n","    --opt adamw \\\n","    --lr 1e-3 \\\n","    --drop_path 0.3 \\\n","    --clip_grad 5.0 \\\n","    --layer_decay 0.9 \\\n","    --opt_betas 0.9 0.999 \\\n","    --weight_decay 0.1 \\\n","    --warmup_epochs 5 \\\n","    --epochs 35 \\\n","    --test_num_segment 5 \\\n","    --test_num_crop 3 \\\n","    --dist_eval --enable_deepspeed"],"metadata":{"id":"7suwdKA7yLcY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1705453368093,"user_tz":300,"elapsed":7536,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"231a628d-710d-43b8-dfca-602236a02e1c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-01-17 01:02:42,376] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n","usage: VideoMAE fine-tuning and evaluation script for action classification\n","       [--batch_size BATCH_SIZE] [--epochs EPOCHS] [--update_freq UPDATE_FREQ]\n","       [--save_ckpt_freq SAVE_CKPT_FREQ] [--model MODEL] [--tubelet_size TUBELET_SIZE]\n","       [--input_size INPUT_SIZE] [--with_checkpoint] [--drop PCT] [--attn_drop_rate PCT]\n","       [--drop_path PCT] [--head_drop_rate PCT] [--disable_eval_during_finetuning] [--model_ema]\n","       [--model_ema_decay MODEL_EMA_DECAY] [--model_ema_force_cpu] [--opt OPTIMIZER]\n","       [--opt_eps EPSILON] [--opt_betas BETA [BETA ...]] [--clip_grad NORM] [--momentum M]\n","       [--weight_decay WEIGHT_DECAY] [--weight_decay_end WEIGHT_DECAY_END] [--lr LR]\n","       [--layer_decay LAYER_DECAY] [--warmup_lr LR] [--min_lr LR] [--warmup_epochs N]\n","       [--warmup_steps N] [--color_jitter PCT] [--num_sample NUM_SAMPLE] [--aa NAME]\n","       [--smoothing SMOOTHING] [--train_interpolation TRAIN_INTERPOLATION] [--crop_pct CROP_PCT]\n","       [--short_side_size SHORT_SIDE_SIZE] [--test_num_segment TEST_NUM_SEGMENT]\n","       [--test_num_crop TEST_NUM_CROP] [--reprob PCT] [--remode REMODE] [--recount RECOUNT]\n","       [--resplit] [--mixup MIXUP] [--cutmix CUTMIX]\n","       [--cutmix_minmax CUTMIX_MINMAX [CUTMIX_MINMAX ...]] [--mixup_prob MIXUP_PROB]\n","       [--mixup_switch_prob MIXUP_SWITCH_PROB] [--mixup_mode MIXUP_MODE] [--finetune FINETUNE]\n","       [--model_key MODEL_KEY] [--model_prefix MODEL_PREFIX] [--init_scale INIT_SCALE]\n","       [--use_mean_pooling] [--use_cls] [--data_path DATA_PATH] [--data_root DATA_ROOT]\n","       [--eval_data_path EVAL_DATA_PATH] [--nb_classes NB_CLASSES]\n","       [--imagenet_default_mean_and_std] [--num_segments NUM_SEGMENTS] [--num_frames NUM_FRAMES]\n","       [--sampling_rate SAMPLING_RATE] [--sparse_sample]\n","       [--data_set {Kinetics-400,Kinetics-600,Kinetics-700,SSV2,UCF101,HMDB51,Diving48,Kinetics-710,MIT}]\n","       [--fname_tmpl FNAME_TMPL] [--start_idx START_IDX] [--output_dir OUTPUT_DIR]\n","       [--log_dir LOG_DIR] [--device DEVICE] [--seed SEED] [--resume RESUME] [--auto_resume]\n","       [--no_auto_resume] [--save_ckpt] [--no_save_ckpt] [--start_epoch N] [--eval] [--validation]\n","       [--dist_eval] [--num_workers NUM_WORKERS] [--pin_mem] [--no_pin_mem]\n","       [--world_size WORLD_SIZE] [--local_rank LOCAL_RANK] [--dist_on_itp] [--dist_url DIST_URL]\n","       [--enable_deepspeed]\n","VideoMAE fine-tuning and evaluation script for action classification: error: argument --data_path: expected one argument\n"]}]},{"cell_type":"markdown","source":["\n","#Model Inference"],"metadata":{"id":"Zh28nehNr76i"}},{"cell_type":"code","source":["import argparse\n","from argparse import Namespace\n","import datetime\n","import json\n","import os\n","import random\n","import time\n","from collections import OrderedDict\n","from functools import partial\n","from pathlib import Path\n","\n","import deepspeed\n","import numpy as np\n","import torch\n","import torch.backends.cudnn as cudnn\n","from timm.data.mixup import Mixup\n","from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n","from timm.models import create_model\n","from timm.utils import ModelEma\n","\n","# NOTE: Do not comment `import models`, it is used to register models\n","import models  # noqa: F401\n","import utils\n","from dataset import build_dataset\n","from engine_for_finetuning import (\n","    final_test,\n","    merge,\n","    train_one_epoch,\n","    validation_one_epoch,\n",")\n","from optim_factory import (\n","    LayerDecayValueAssigner,\n","    create_optimizer,\n","    get_parameter_groups,\n",")\n","from utils import NativeScalerWithGradNormCount as NativeScaler\n","from utils import multiple_samples_collate\n","\n","args = Namespace(\n","    batch_size=3,\n","    epochs=35,\n","    update_freq=1,\n","    save_ckpt_freq=10,\n","    model='vit_giant_patch14_224',\n","    tubelet_size=2,\n","    input_size=224,\n","    with_checkpoint=False,\n","    drop=0.0,\n","    attn_drop_rate=0.0,\n","    drop_path=0.3,\n","    head_drop_rate=0.0,\n","    disable_eval_during_finetuning=False,\n","    model_ema=False,\n","    model_ema_decay=0.9999,\n","    model_ema_force_cpu=False,\n","    opt='adamw',\n","    opt_eps=1e-08,\n","    opt_betas=[0.9, 0.999],\n","    clip_grad=5.0,\n","    momentum=0.9,\n","    weight_decay=0.1,\n","    weight_decay_end=None,\n","    lr=0.001,\n","    layer_decay=0.9,\n","    warmup_lr=1e-08,\n","    min_lr=1e-06,\n","    warmup_epochs=5,\n","    warmup_steps=-1,\n","    color_jitter=0.4,\n","    num_sample=2,\n","    aa='rand-m7-n4-mstd0.5-inc1',\n","    smoothing=0.1,\n","    train_interpolation='bicubic',\n","    crop_pct=None,\n","    short_side_size=224,\n","    test_num_segment=5,\n","    test_num_crop=3,\n","    reprob=0.25,\n","    remode='pixel',\n","    recount=1,\n","    resplit=False,\n","    mixup=0.8,\n","    cutmix=1.0,\n","    cutmix_minmax=None,\n","    mixup_prob=1.0,\n","    mixup_switch_prob=0.5,\n","    mixup_mode='batch',\n","    finetune='/content/drive/MyDrive/vit_g_hybrid_pt_1200e_k710_ft.pth',\n","    model_key='model|module',\n","    model_prefix='',\n","    init_scale=0.001,\n","    use_mean_pooling=True,\n","    data_path='/content/data/k710',\n","    data_root='',\n","    eval_data_path=None,\n","    nb_classes=710,\n","    imagenet_default_mean_and_std=True,\n","    num_segments=1,\n","    num_frames=16,\n","    sampling_rate=4,\n","    sparse_sample=False,\n","    data_set='Kinetics-710',\n","    fname_tmpl='img_{:05}.jpg',\n","    start_idx=1,\n","    output_dir='content/output',\n","    log_dir='content/output',\n","    device='cuda',\n","    seed=0,\n","    resume='',\n","    auto_resume=True,\n","    save_ckpt=True,\n","    start_epoch=0,\n","    eval=False,\n","    validation=False,\n","    dist_eval=True,\n","    num_workers=10,\n","    pin_mem=True,\n","    world_size=1,\n","    local_rank=-1,\n","    dist_on_itp=False,\n","    dist_url='env://',\n","    enable_deepspeed=True,\n","    deepspeed=False,\n","    deepspeed_config='content/output/deepspeed_config.json',\n","    deepscale=False,\n","    deepscale_config=None,\n","    deepspeed_mpi=False,\n","    distributed=False\n","  )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deLHbly18lEl","executionInfo":{"status":"ok","timestamp":1708386825334,"user_tz":300,"elapsed":6575,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"ee639ee7-a371-4b0a-d44a-aa13c25e4b82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[2024-02-19 23:53:40,124] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"]}]},{"cell_type":"code","source":["trained_model = create_model(\n","    args.model,\n","    img_size=args.input_size,\n","    pretrained=False,\n","    num_classes=args.nb_classes,\n","    all_frames=args.num_frames * args.test_num_segment,\n","    tubelet_size=args.tubelet_size,\n","    drop_rate=args.drop,\n","    drop_path_rate=args.drop_path,\n","    attn_drop_rate=args.attn_drop_rate,\n","    head_drop_rate=args.head_drop_rate,\n","    drop_block_rate=None,\n","    use_mean_pooling=args.use_mean_pooling,\n","    init_scale=args.init_scale,\n","    with_cp=args.with_checkpoint,\n","  )"],"metadata":{"id":"uGLqec_Ar_DR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Stats"],"metadata":{"id":"r3PaZB6DkMSo"}},{"cell_type":"code","source":["n_parameters = sum(p.numel() for p in trained_model.parameters() if p.requires_grad)\n","n_layers = trained_model.get_num_layers()\n","\n","print(f'num parameters: {n_parameters}')\n","print(f'num layers: {n_layers}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EWPi9QnEZQ21","executionInfo":{"status":"ok","timestamp":1708386882869,"user_tz":300,"elapsed":302,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"c4a23ec1-f383-4857-e8fb-ec005c237666"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["num parameters: 1012611142\n","num layers: 40\n"]}]},{"cell_type":"code","source":["checkpoint_model = torch.load(args.finetune, map_location='cpu')\n","checkpoint_model = checkpoint_model[\"module\"]\n","state_dict = trained_model.state_dict()\n","\n","for old_key in list(checkpoint_model.keys()):\n","  if old_key.startswith('_orig_mod.'):\n","    new_key = old_key[10:]\n","    checkpoint_model[new_key] = checkpoint_model.pop(old_key)\n","\n","all_keys = list(checkpoint_model.keys())\n","new_dict = OrderedDict()\n","for key in all_keys:\n","  if key.startswith('backbone.'):\n","    new_dict[key[9:]] = checkpoint_model[key]\n","  elif key.startswith('encoder.'):\n","    new_dict[key[8:]] = checkpoint_model[key]\n","  else:\n","    new_dict[key] = checkpoint_model[key]\n","checkpoint_model = new_dict"],"metadata":{"id":"Tw2f_hkjAm1t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["utils.load_state_dict(\n","    trained_model, checkpoint_model, prefix=args.model_prefix)\n","\n","optimizer = create_optimizer(\n","    args,\n","    trained_model,\n","    skip_list=trained_model.no_weight_decay(),\n","    get_num_layer=None,\n","    get_layer_scale=None\n","  )\n","\n","loss_scaler = NativeScaler()\n","\n","utils.auto_load_model(\n","    args=args,\n","    model=trained_model,\n","    model_without_ddp=trained_model,\n","    optimizer=optimizer,\n","    loss_scaler=loss_scaler,\n","    model_ema=None\n","  )\n","\n","trained_model"],"metadata":{"id":"h1ROHrjl9-O3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708386943884,"user_tz":300,"elapsed":345,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"6f408b82-d337-49c2-d8a5-f39a2f1dd57d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Param groups = {\n","  \"decay\": {\n","    \"weight_decay\": 0.1,\n","    \"params\": [\n","      \"patch_embed.proj.weight\",\n","      \"blocks.0.attn.qkv.weight\",\n","      \"blocks.0.attn.proj.weight\",\n","      \"blocks.0.mlp.fc1.weight\",\n","      \"blocks.0.mlp.fc2.weight\",\n","      \"blocks.1.attn.qkv.weight\",\n","      \"blocks.1.attn.proj.weight\",\n","      \"blocks.1.mlp.fc1.weight\",\n","      \"blocks.1.mlp.fc2.weight\",\n","      \"blocks.2.attn.qkv.weight\",\n","      \"blocks.2.attn.proj.weight\",\n","      \"blocks.2.mlp.fc1.weight\",\n","      \"blocks.2.mlp.fc2.weight\",\n","      \"blocks.3.attn.qkv.weight\",\n","      \"blocks.3.attn.proj.weight\",\n","      \"blocks.3.mlp.fc1.weight\",\n","      \"blocks.3.mlp.fc2.weight\",\n","      \"blocks.4.attn.qkv.weight\",\n","      \"blocks.4.attn.proj.weight\",\n","      \"blocks.4.mlp.fc1.weight\",\n","      \"blocks.4.mlp.fc2.weight\",\n","      \"blocks.5.attn.qkv.weight\",\n","      \"blocks.5.attn.proj.weight\",\n","      \"blocks.5.mlp.fc1.weight\",\n","      \"blocks.5.mlp.fc2.weight\",\n","      \"blocks.6.attn.qkv.weight\",\n","      \"blocks.6.attn.proj.weight\",\n","      \"blocks.6.mlp.fc1.weight\",\n","      \"blocks.6.mlp.fc2.weight\",\n","      \"blocks.7.attn.qkv.weight\",\n","      \"blocks.7.attn.proj.weight\",\n","      \"blocks.7.mlp.fc1.weight\",\n","      \"blocks.7.mlp.fc2.weight\",\n","      \"blocks.8.attn.qkv.weight\",\n","      \"blocks.8.attn.proj.weight\",\n","      \"blocks.8.mlp.fc1.weight\",\n","      \"blocks.8.mlp.fc2.weight\",\n","      \"blocks.9.attn.qkv.weight\",\n","      \"blocks.9.attn.proj.weight\",\n","      \"blocks.9.mlp.fc1.weight\",\n","      \"blocks.9.mlp.fc2.weight\",\n","      \"blocks.10.attn.qkv.weight\",\n","      \"blocks.10.attn.proj.weight\",\n","      \"blocks.10.mlp.fc1.weight\",\n","      \"blocks.10.mlp.fc2.weight\",\n","      \"blocks.11.attn.qkv.weight\",\n","      \"blocks.11.attn.proj.weight\",\n","      \"blocks.11.mlp.fc1.weight\",\n","      \"blocks.11.mlp.fc2.weight\",\n","      \"blocks.12.attn.qkv.weight\",\n","      \"blocks.12.attn.proj.weight\",\n","      \"blocks.12.mlp.fc1.weight\",\n","      \"blocks.12.mlp.fc2.weight\",\n","      \"blocks.13.attn.qkv.weight\",\n","      \"blocks.13.attn.proj.weight\",\n","      \"blocks.13.mlp.fc1.weight\",\n","      \"blocks.13.mlp.fc2.weight\",\n","      \"blocks.14.attn.qkv.weight\",\n","      \"blocks.14.attn.proj.weight\",\n","      \"blocks.14.mlp.fc1.weight\",\n","      \"blocks.14.mlp.fc2.weight\",\n","      \"blocks.15.attn.qkv.weight\",\n","      \"blocks.15.attn.proj.weight\",\n","      \"blocks.15.mlp.fc1.weight\",\n","      \"blocks.15.mlp.fc2.weight\",\n","      \"blocks.16.attn.qkv.weight\",\n","      \"blocks.16.attn.proj.weight\",\n","      \"blocks.16.mlp.fc1.weight\",\n","      \"blocks.16.mlp.fc2.weight\",\n","      \"blocks.17.attn.qkv.weight\",\n","      \"blocks.17.attn.proj.weight\",\n","      \"blocks.17.mlp.fc1.weight\",\n","      \"blocks.17.mlp.fc2.weight\",\n","      \"blocks.18.attn.qkv.weight\",\n","      \"blocks.18.attn.proj.weight\",\n","      \"blocks.18.mlp.fc1.weight\",\n","      \"blocks.18.mlp.fc2.weight\",\n","      \"blocks.19.attn.qkv.weight\",\n","      \"blocks.19.attn.proj.weight\",\n","      \"blocks.19.mlp.fc1.weight\",\n","      \"blocks.19.mlp.fc2.weight\",\n","      \"blocks.20.attn.qkv.weight\",\n","      \"blocks.20.attn.proj.weight\",\n","      \"blocks.20.mlp.fc1.weight\",\n","      \"blocks.20.mlp.fc2.weight\",\n","      \"blocks.21.attn.qkv.weight\",\n","      \"blocks.21.attn.proj.weight\",\n","      \"blocks.21.mlp.fc1.weight\",\n","      \"blocks.21.mlp.fc2.weight\",\n","      \"blocks.22.attn.qkv.weight\",\n","      \"blocks.22.attn.proj.weight\",\n","      \"blocks.22.mlp.fc1.weight\",\n","      \"blocks.22.mlp.fc2.weight\",\n","      \"blocks.23.attn.qkv.weight\",\n","      \"blocks.23.attn.proj.weight\",\n","      \"blocks.23.mlp.fc1.weight\",\n","      \"blocks.23.mlp.fc2.weight\",\n","      \"blocks.24.attn.qkv.weight\",\n","      \"blocks.24.attn.proj.weight\",\n","      \"blocks.24.mlp.fc1.weight\",\n","      \"blocks.24.mlp.fc2.weight\",\n","      \"blocks.25.attn.qkv.weight\",\n","      \"blocks.25.attn.proj.weight\",\n","      \"blocks.25.mlp.fc1.weight\",\n","      \"blocks.25.mlp.fc2.weight\",\n","      \"blocks.26.attn.qkv.weight\",\n","      \"blocks.26.attn.proj.weight\",\n","      \"blocks.26.mlp.fc1.weight\",\n","      \"blocks.26.mlp.fc2.weight\",\n","      \"blocks.27.attn.qkv.weight\",\n","      \"blocks.27.attn.proj.weight\",\n","      \"blocks.27.mlp.fc1.weight\",\n","      \"blocks.27.mlp.fc2.weight\",\n","      \"blocks.28.attn.qkv.weight\",\n","      \"blocks.28.attn.proj.weight\",\n","      \"blocks.28.mlp.fc1.weight\",\n","      \"blocks.28.mlp.fc2.weight\",\n","      \"blocks.29.attn.qkv.weight\",\n","      \"blocks.29.attn.proj.weight\",\n","      \"blocks.29.mlp.fc1.weight\",\n","      \"blocks.29.mlp.fc2.weight\",\n","      \"blocks.30.attn.qkv.weight\",\n","      \"blocks.30.attn.proj.weight\",\n","      \"blocks.30.mlp.fc1.weight\",\n","      \"blocks.30.mlp.fc2.weight\",\n","      \"blocks.31.attn.qkv.weight\",\n","      \"blocks.31.attn.proj.weight\",\n","      \"blocks.31.mlp.fc1.weight\",\n","      \"blocks.31.mlp.fc2.weight\",\n","      \"blocks.32.attn.qkv.weight\",\n","      \"blocks.32.attn.proj.weight\",\n","      \"blocks.32.mlp.fc1.weight\",\n","      \"blocks.32.mlp.fc2.weight\",\n","      \"blocks.33.attn.qkv.weight\",\n","      \"blocks.33.attn.proj.weight\",\n","      \"blocks.33.mlp.fc1.weight\",\n","      \"blocks.33.mlp.fc2.weight\",\n","      \"blocks.34.attn.qkv.weight\",\n","      \"blocks.34.attn.proj.weight\",\n","      \"blocks.34.mlp.fc1.weight\",\n","      \"blocks.34.mlp.fc2.weight\",\n","      \"blocks.35.attn.qkv.weight\",\n","      \"blocks.35.attn.proj.weight\",\n","      \"blocks.35.mlp.fc1.weight\",\n","      \"blocks.35.mlp.fc2.weight\",\n","      \"blocks.36.attn.qkv.weight\",\n","      \"blocks.36.attn.proj.weight\",\n","      \"blocks.36.mlp.fc1.weight\",\n","      \"blocks.36.mlp.fc2.weight\",\n","      \"blocks.37.attn.qkv.weight\",\n","      \"blocks.37.attn.proj.weight\",\n","      \"blocks.37.mlp.fc1.weight\",\n","      \"blocks.37.mlp.fc2.weight\",\n","      \"blocks.38.attn.qkv.weight\",\n","      \"blocks.38.attn.proj.weight\",\n","      \"blocks.38.mlp.fc1.weight\",\n","      \"blocks.38.mlp.fc2.weight\",\n","      \"blocks.39.attn.qkv.weight\",\n","      \"blocks.39.attn.proj.weight\",\n","      \"blocks.39.mlp.fc1.weight\",\n","      \"blocks.39.mlp.fc2.weight\",\n","      \"head.weight\"\n","    ],\n","    \"lr_scale\": 1.0\n","  },\n","  \"no_decay\": {\n","    \"weight_decay\": 0.0,\n","    \"params\": [\n","      \"patch_embed.proj.bias\",\n","      \"blocks.0.norm1.weight\",\n","      \"blocks.0.norm1.bias\",\n","      \"blocks.0.attn.q_bias\",\n","      \"blocks.0.attn.v_bias\",\n","      \"blocks.0.attn.proj.bias\",\n","      \"blocks.0.norm2.weight\",\n","      \"blocks.0.norm2.bias\",\n","      \"blocks.0.mlp.fc1.bias\",\n","      \"blocks.0.mlp.fc2.bias\",\n","      \"blocks.1.norm1.weight\",\n","      \"blocks.1.norm1.bias\",\n","      \"blocks.1.attn.q_bias\",\n","      \"blocks.1.attn.v_bias\",\n","      \"blocks.1.attn.proj.bias\",\n","      \"blocks.1.norm2.weight\",\n","      \"blocks.1.norm2.bias\",\n","      \"blocks.1.mlp.fc1.bias\",\n","      \"blocks.1.mlp.fc2.bias\",\n","      \"blocks.2.norm1.weight\",\n","      \"blocks.2.norm1.bias\",\n","      \"blocks.2.attn.q_bias\",\n","      \"blocks.2.attn.v_bias\",\n","      \"blocks.2.attn.proj.bias\",\n","      \"blocks.2.norm2.weight\",\n","      \"blocks.2.norm2.bias\",\n","      \"blocks.2.mlp.fc1.bias\",\n","      \"blocks.2.mlp.fc2.bias\",\n","      \"blocks.3.norm1.weight\",\n","      \"blocks.3.norm1.bias\",\n","      \"blocks.3.attn.q_bias\",\n","      \"blocks.3.attn.v_bias\",\n","      \"blocks.3.attn.proj.bias\",\n","      \"blocks.3.norm2.weight\",\n","      \"blocks.3.norm2.bias\",\n","      \"blocks.3.mlp.fc1.bias\",\n","      \"blocks.3.mlp.fc2.bias\",\n","      \"blocks.4.norm1.weight\",\n","      \"blocks.4.norm1.bias\",\n","      \"blocks.4.attn.q_bias\",\n","      \"blocks.4.attn.v_bias\",\n","      \"blocks.4.attn.proj.bias\",\n","      \"blocks.4.norm2.weight\",\n","      \"blocks.4.norm2.bias\",\n","      \"blocks.4.mlp.fc1.bias\",\n","      \"blocks.4.mlp.fc2.bias\",\n","      \"blocks.5.norm1.weight\",\n","      \"blocks.5.norm1.bias\",\n","      \"blocks.5.attn.q_bias\",\n","      \"blocks.5.attn.v_bias\",\n","      \"blocks.5.attn.proj.bias\",\n","      \"blocks.5.norm2.weight\",\n","      \"blocks.5.norm2.bias\",\n","      \"blocks.5.mlp.fc1.bias\",\n","      \"blocks.5.mlp.fc2.bias\",\n","      \"blocks.6.norm1.weight\",\n","      \"blocks.6.norm1.bias\",\n","      \"blocks.6.attn.q_bias\",\n","      \"blocks.6.attn.v_bias\",\n","      \"blocks.6.attn.proj.bias\",\n","      \"blocks.6.norm2.weight\",\n","      \"blocks.6.norm2.bias\",\n","      \"blocks.6.mlp.fc1.bias\",\n","      \"blocks.6.mlp.fc2.bias\",\n","      \"blocks.7.norm1.weight\",\n","      \"blocks.7.norm1.bias\",\n","      \"blocks.7.attn.q_bias\",\n","      \"blocks.7.attn.v_bias\",\n","      \"blocks.7.attn.proj.bias\",\n","      \"blocks.7.norm2.weight\",\n","      \"blocks.7.norm2.bias\",\n","      \"blocks.7.mlp.fc1.bias\",\n","      \"blocks.7.mlp.fc2.bias\",\n","      \"blocks.8.norm1.weight\",\n","      \"blocks.8.norm1.bias\",\n","      \"blocks.8.attn.q_bias\",\n","      \"blocks.8.attn.v_bias\",\n","      \"blocks.8.attn.proj.bias\",\n","      \"blocks.8.norm2.weight\",\n","      \"blocks.8.norm2.bias\",\n","      \"blocks.8.mlp.fc1.bias\",\n","      \"blocks.8.mlp.fc2.bias\",\n","      \"blocks.9.norm1.weight\",\n","      \"blocks.9.norm1.bias\",\n","      \"blocks.9.attn.q_bias\",\n","      \"blocks.9.attn.v_bias\",\n","      \"blocks.9.attn.proj.bias\",\n","      \"blocks.9.norm2.weight\",\n","      \"blocks.9.norm2.bias\",\n","      \"blocks.9.mlp.fc1.bias\",\n","      \"blocks.9.mlp.fc2.bias\",\n","      \"blocks.10.norm1.weight\",\n","      \"blocks.10.norm1.bias\",\n","      \"blocks.10.attn.q_bias\",\n","      \"blocks.10.attn.v_bias\",\n","      \"blocks.10.attn.proj.bias\",\n","      \"blocks.10.norm2.weight\",\n","      \"blocks.10.norm2.bias\",\n","      \"blocks.10.mlp.fc1.bias\",\n","      \"blocks.10.mlp.fc2.bias\",\n","      \"blocks.11.norm1.weight\",\n","      \"blocks.11.norm1.bias\",\n","      \"blocks.11.attn.q_bias\",\n","      \"blocks.11.attn.v_bias\",\n","      \"blocks.11.attn.proj.bias\",\n","      \"blocks.11.norm2.weight\",\n","      \"blocks.11.norm2.bias\",\n","      \"blocks.11.mlp.fc1.bias\",\n","      \"blocks.11.mlp.fc2.bias\",\n","      \"blocks.12.norm1.weight\",\n","      \"blocks.12.norm1.bias\",\n","      \"blocks.12.attn.q_bias\",\n","      \"blocks.12.attn.v_bias\",\n","      \"blocks.12.attn.proj.bias\",\n","      \"blocks.12.norm2.weight\",\n","      \"blocks.12.norm2.bias\",\n","      \"blocks.12.mlp.fc1.bias\",\n","      \"blocks.12.mlp.fc2.bias\",\n","      \"blocks.13.norm1.weight\",\n","      \"blocks.13.norm1.bias\",\n","      \"blocks.13.attn.q_bias\",\n","      \"blocks.13.attn.v_bias\",\n","      \"blocks.13.attn.proj.bias\",\n","      \"blocks.13.norm2.weight\",\n","      \"blocks.13.norm2.bias\",\n","      \"blocks.13.mlp.fc1.bias\",\n","      \"blocks.13.mlp.fc2.bias\",\n","      \"blocks.14.norm1.weight\",\n","      \"blocks.14.norm1.bias\",\n","      \"blocks.14.attn.q_bias\",\n","      \"blocks.14.attn.v_bias\",\n","      \"blocks.14.attn.proj.bias\",\n","      \"blocks.14.norm2.weight\",\n","      \"blocks.14.norm2.bias\",\n","      \"blocks.14.mlp.fc1.bias\",\n","      \"blocks.14.mlp.fc2.bias\",\n","      \"blocks.15.norm1.weight\",\n","      \"blocks.15.norm1.bias\",\n","      \"blocks.15.attn.q_bias\",\n","      \"blocks.15.attn.v_bias\",\n","      \"blocks.15.attn.proj.bias\",\n","      \"blocks.15.norm2.weight\",\n","      \"blocks.15.norm2.bias\",\n","      \"blocks.15.mlp.fc1.bias\",\n","      \"blocks.15.mlp.fc2.bias\",\n","      \"blocks.16.norm1.weight\",\n","      \"blocks.16.norm1.bias\",\n","      \"blocks.16.attn.q_bias\",\n","      \"blocks.16.attn.v_bias\",\n","      \"blocks.16.attn.proj.bias\",\n","      \"blocks.16.norm2.weight\",\n","      \"blocks.16.norm2.bias\",\n","      \"blocks.16.mlp.fc1.bias\",\n","      \"blocks.16.mlp.fc2.bias\",\n","      \"blocks.17.norm1.weight\",\n","      \"blocks.17.norm1.bias\",\n","      \"blocks.17.attn.q_bias\",\n","      \"blocks.17.attn.v_bias\",\n","      \"blocks.17.attn.proj.bias\",\n","      \"blocks.17.norm2.weight\",\n","      \"blocks.17.norm2.bias\",\n","      \"blocks.17.mlp.fc1.bias\",\n","      \"blocks.17.mlp.fc2.bias\",\n","      \"blocks.18.norm1.weight\",\n","      \"blocks.18.norm1.bias\",\n","      \"blocks.18.attn.q_bias\",\n","      \"blocks.18.attn.v_bias\",\n","      \"blocks.18.attn.proj.bias\",\n","      \"blocks.18.norm2.weight\",\n","      \"blocks.18.norm2.bias\",\n","      \"blocks.18.mlp.fc1.bias\",\n","      \"blocks.18.mlp.fc2.bias\",\n","      \"blocks.19.norm1.weight\",\n","      \"blocks.19.norm1.bias\",\n","      \"blocks.19.attn.q_bias\",\n","      \"blocks.19.attn.v_bias\",\n","      \"blocks.19.attn.proj.bias\",\n","      \"blocks.19.norm2.weight\",\n","      \"blocks.19.norm2.bias\",\n","      \"blocks.19.mlp.fc1.bias\",\n","      \"blocks.19.mlp.fc2.bias\",\n","      \"blocks.20.norm1.weight\",\n","      \"blocks.20.norm1.bias\",\n","      \"blocks.20.attn.q_bias\",\n","      \"blocks.20.attn.v_bias\",\n","      \"blocks.20.attn.proj.bias\",\n","      \"blocks.20.norm2.weight\",\n","      \"blocks.20.norm2.bias\",\n","      \"blocks.20.mlp.fc1.bias\",\n","      \"blocks.20.mlp.fc2.bias\",\n","      \"blocks.21.norm1.weight\",\n","      \"blocks.21.norm1.bias\",\n","      \"blocks.21.attn.q_bias\",\n","      \"blocks.21.attn.v_bias\",\n","      \"blocks.21.attn.proj.bias\",\n","      \"blocks.21.norm2.weight\",\n","      \"blocks.21.norm2.bias\",\n","      \"blocks.21.mlp.fc1.bias\",\n","      \"blocks.21.mlp.fc2.bias\",\n","      \"blocks.22.norm1.weight\",\n","      \"blocks.22.norm1.bias\",\n","      \"blocks.22.attn.q_bias\",\n","      \"blocks.22.attn.v_bias\",\n","      \"blocks.22.attn.proj.bias\",\n","      \"blocks.22.norm2.weight\",\n","      \"blocks.22.norm2.bias\",\n","      \"blocks.22.mlp.fc1.bias\",\n","      \"blocks.22.mlp.fc2.bias\",\n","      \"blocks.23.norm1.weight\",\n","      \"blocks.23.norm1.bias\",\n","      \"blocks.23.attn.q_bias\",\n","      \"blocks.23.attn.v_bias\",\n","      \"blocks.23.attn.proj.bias\",\n","      \"blocks.23.norm2.weight\",\n","      \"blocks.23.norm2.bias\",\n","      \"blocks.23.mlp.fc1.bias\",\n","      \"blocks.23.mlp.fc2.bias\",\n","      \"blocks.24.norm1.weight\",\n","      \"blocks.24.norm1.bias\",\n","      \"blocks.24.attn.q_bias\",\n","      \"blocks.24.attn.v_bias\",\n","      \"blocks.24.attn.proj.bias\",\n","      \"blocks.24.norm2.weight\",\n","      \"blocks.24.norm2.bias\",\n","      \"blocks.24.mlp.fc1.bias\",\n","      \"blocks.24.mlp.fc2.bias\",\n","      \"blocks.25.norm1.weight\",\n","      \"blocks.25.norm1.bias\",\n","      \"blocks.25.attn.q_bias\",\n","      \"blocks.25.attn.v_bias\",\n","      \"blocks.25.attn.proj.bias\",\n","      \"blocks.25.norm2.weight\",\n","      \"blocks.25.norm2.bias\",\n","      \"blocks.25.mlp.fc1.bias\",\n","      \"blocks.25.mlp.fc2.bias\",\n","      \"blocks.26.norm1.weight\",\n","      \"blocks.26.norm1.bias\",\n","      \"blocks.26.attn.q_bias\",\n","      \"blocks.26.attn.v_bias\",\n","      \"blocks.26.attn.proj.bias\",\n","      \"blocks.26.norm2.weight\",\n","      \"blocks.26.norm2.bias\",\n","      \"blocks.26.mlp.fc1.bias\",\n","      \"blocks.26.mlp.fc2.bias\",\n","      \"blocks.27.norm1.weight\",\n","      \"blocks.27.norm1.bias\",\n","      \"blocks.27.attn.q_bias\",\n","      \"blocks.27.attn.v_bias\",\n","      \"blocks.27.attn.proj.bias\",\n","      \"blocks.27.norm2.weight\",\n","      \"blocks.27.norm2.bias\",\n","      \"blocks.27.mlp.fc1.bias\",\n","      \"blocks.27.mlp.fc2.bias\",\n","      \"blocks.28.norm1.weight\",\n","      \"blocks.28.norm1.bias\",\n","      \"blocks.28.attn.q_bias\",\n","      \"blocks.28.attn.v_bias\",\n","      \"blocks.28.attn.proj.bias\",\n","      \"blocks.28.norm2.weight\",\n","      \"blocks.28.norm2.bias\",\n","      \"blocks.28.mlp.fc1.bias\",\n","      \"blocks.28.mlp.fc2.bias\",\n","      \"blocks.29.norm1.weight\",\n","      \"blocks.29.norm1.bias\",\n","      \"blocks.29.attn.q_bias\",\n","      \"blocks.29.attn.v_bias\",\n","      \"blocks.29.attn.proj.bias\",\n","      \"blocks.29.norm2.weight\",\n","      \"blocks.29.norm2.bias\",\n","      \"blocks.29.mlp.fc1.bias\",\n","      \"blocks.29.mlp.fc2.bias\",\n","      \"blocks.30.norm1.weight\",\n","      \"blocks.30.norm1.bias\",\n","      \"blocks.30.attn.q_bias\",\n","      \"blocks.30.attn.v_bias\",\n","      \"blocks.30.attn.proj.bias\",\n","      \"blocks.30.norm2.weight\",\n","      \"blocks.30.norm2.bias\",\n","      \"blocks.30.mlp.fc1.bias\",\n","      \"blocks.30.mlp.fc2.bias\",\n","      \"blocks.31.norm1.weight\",\n","      \"blocks.31.norm1.bias\",\n","      \"blocks.31.attn.q_bias\",\n","      \"blocks.31.attn.v_bias\",\n","      \"blocks.31.attn.proj.bias\",\n","      \"blocks.31.norm2.weight\",\n","      \"blocks.31.norm2.bias\",\n","      \"blocks.31.mlp.fc1.bias\",\n","      \"blocks.31.mlp.fc2.bias\",\n","      \"blocks.32.norm1.weight\",\n","      \"blocks.32.norm1.bias\",\n","      \"blocks.32.attn.q_bias\",\n","      \"blocks.32.attn.v_bias\",\n","      \"blocks.32.attn.proj.bias\",\n","      \"blocks.32.norm2.weight\",\n","      \"blocks.32.norm2.bias\",\n","      \"blocks.32.mlp.fc1.bias\",\n","      \"blocks.32.mlp.fc2.bias\",\n","      \"blocks.33.norm1.weight\",\n","      \"blocks.33.norm1.bias\",\n","      \"blocks.33.attn.q_bias\",\n","      \"blocks.33.attn.v_bias\",\n","      \"blocks.33.attn.proj.bias\",\n","      \"blocks.33.norm2.weight\",\n","      \"blocks.33.norm2.bias\",\n","      \"blocks.33.mlp.fc1.bias\",\n","      \"blocks.33.mlp.fc2.bias\",\n","      \"blocks.34.norm1.weight\",\n","      \"blocks.34.norm1.bias\",\n","      \"blocks.34.attn.q_bias\",\n","      \"blocks.34.attn.v_bias\",\n","      \"blocks.34.attn.proj.bias\",\n","      \"blocks.34.norm2.weight\",\n","      \"blocks.34.norm2.bias\",\n","      \"blocks.34.mlp.fc1.bias\",\n","      \"blocks.34.mlp.fc2.bias\",\n","      \"blocks.35.norm1.weight\",\n","      \"blocks.35.norm1.bias\",\n","      \"blocks.35.attn.q_bias\",\n","      \"blocks.35.attn.v_bias\",\n","      \"blocks.35.attn.proj.bias\",\n","      \"blocks.35.norm2.weight\",\n","      \"blocks.35.norm2.bias\",\n","      \"blocks.35.mlp.fc1.bias\",\n","      \"blocks.35.mlp.fc2.bias\",\n","      \"blocks.36.norm1.weight\",\n","      \"blocks.36.norm1.bias\",\n","      \"blocks.36.attn.q_bias\",\n","      \"blocks.36.attn.v_bias\",\n","      \"blocks.36.attn.proj.bias\",\n","      \"blocks.36.norm2.weight\",\n","      \"blocks.36.norm2.bias\",\n","      \"blocks.36.mlp.fc1.bias\",\n","      \"blocks.36.mlp.fc2.bias\",\n","      \"blocks.37.norm1.weight\",\n","      \"blocks.37.norm1.bias\",\n","      \"blocks.37.attn.q_bias\",\n","      \"blocks.37.attn.v_bias\",\n","      \"blocks.37.attn.proj.bias\",\n","      \"blocks.37.norm2.weight\",\n","      \"blocks.37.norm2.bias\",\n","      \"blocks.37.mlp.fc1.bias\",\n","      \"blocks.37.mlp.fc2.bias\",\n","      \"blocks.38.norm1.weight\",\n","      \"blocks.38.norm1.bias\",\n","      \"blocks.38.attn.q_bias\",\n","      \"blocks.38.attn.v_bias\",\n","      \"blocks.38.attn.proj.bias\",\n","      \"blocks.38.norm2.weight\",\n","      \"blocks.38.norm2.bias\",\n","      \"blocks.38.mlp.fc1.bias\",\n","      \"blocks.38.mlp.fc2.bias\",\n","      \"blocks.39.norm1.weight\",\n","      \"blocks.39.norm1.bias\",\n","      \"blocks.39.attn.q_bias\",\n","      \"blocks.39.attn.v_bias\",\n","      \"blocks.39.attn.proj.bias\",\n","      \"blocks.39.norm2.weight\",\n","      \"blocks.39.norm2.bias\",\n","      \"blocks.39.mlp.fc1.bias\",\n","      \"blocks.39.mlp.fc2.bias\",\n","      \"fc_norm.weight\",\n","      \"fc_norm.bias\",\n","      \"head.bias\"\n","    ],\n","    \"lr_scale\": 1.0\n","  }\n","}\n","optimizer settings: {'lr': 0.001, 'weight_decay': 0.0, 'eps': 1e-08, 'betas': [0.9, 0.999]}\n","Auto resume checkpoint: \n"]},{"output_type":"execute_result","data":{"text/plain":["VisionTransformer(\n","  (patch_embed): PatchEmbed(\n","    (proj): Conv3d(3, 1408, kernel_size=(2, 14, 14), stride=(2, 14, 14))\n","  )\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (blocks): ModuleList(\n","    (0): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): Identity()\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (1): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.007692308165132999)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (2): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.015384616330265999)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (3): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.023076925426721573)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (4): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.030769232660531998)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (5): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.03846153989434242)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (6): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.046153850853443146)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (7): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.05384615808725357)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (8): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.061538465321063995)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (9): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.06923077255487442)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (10): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.07692307978868484)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (11): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.08461539447307587)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (12): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.09230770170688629)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (13): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.10000000894069672)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (14): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.10769231617450714)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (15): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.11538462340831757)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (16): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.12307693064212799)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (17): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.13076923787593842)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (18): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.13846154510974884)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (19): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.14615385234355927)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (20): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.1538461595773697)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (21): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.16153846681118011)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (22): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.16923078894615173)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (23): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.17692309617996216)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (24): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.1846153885126114)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (25): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.19230769574642181)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (26): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.20000000298023224)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (27): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.20769231021404266)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (28): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.2153846174478531)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (29): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.2230769246816635)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (30): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.23076924681663513)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (31): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.23846155405044556)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (32): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.24615386128425598)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (33): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.2538461685180664)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (34): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.26153847575187683)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (35): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.26923078298568726)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (36): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.2769230902194977)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (37): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.2846153974533081)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (38): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.29230770468711853)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (39): Block(\n","      (norm1): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (attn): Attention(\n","        (qkv): Linear(in_features=1408, out_features=4224, bias=False)\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): Linear(in_features=1408, out_features=1408, bias=True)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (drop_path): DropPath(p=0.30000001192092896)\n","      (norm2): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","      (mlp): Mlp(\n","        (fc1): Linear(in_features=1408, out_features=6144, bias=True)\n","        (act): GELU(approximate=none)\n","        (fc2): Linear(in_features=6144, out_features=1408, bias=True)\n","        (drop): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): Identity()\n","  (fc_norm): LayerNorm((1408,), eps=1e-06, elementwise_affine=True)\n","  (head_dropout): Dropout(p=0.0, inplace=False)\n","  (head): Linear(in_features=1408, out_features=710, bias=True)\n",")"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Inference with Embedding Output"],"metadata":{"id":"Pm-SrCLl2126"}},{"cell_type":"code","source":["def embedding_output(trained_model, images):\n","  trained_model.eval()\n","\n","  output = trained_model.patch_embed(images)\n","  output = trained_model.pos_drop(output)\n","\n","  for m in trained_model.blocks:\n","    output = m(output)\n","\n","  return output.flatten()\n","\n","images = torch.zeros([1, 3, 80, 224, 224])\n","embedding_output(trained_model, images)"],"metadata":{"id":"O9ol1nFjy6Hn","colab":{"base_uri":"https://localhost:8080/","height":329},"executionInfo":{"status":"error","timestamp":1708386978282,"user_tz":300,"elapsed":4722,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"c56eb3d8-b152-4f6f-91ad-acd24ee1a906"},"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-7ba348ef3066>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0membedding_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-10-7ba348ef3066>\u001b[0m in \u001b[0;36membedding_output\u001b[0;34m(trained_model, images)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/models/modeling_finetune.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma_1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/models/modeling_finetune.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["Inference with Score Output"],"metadata":{"id":"RNbLiR8g25DC"}},{"cell_type":"code","source":["trained_model.eval()\n","\n","images = torch.zeros([1, 3, 80, 224, 224])\n","with torch.cuda.amp.autocast():\n","  output = trained_model(images)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":216},"id":"g6X8saU1gxFV","executionInfo":{"status":"error","timestamp":1708109212188,"user_tz":300,"elapsed":833,"user":{"displayName":"Christopher Kan","userId":"14778444417164088109"}},"outputId":"9d2f346a-4e8a-45fe-a136-cba01d19eedd"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'trained_model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-580ce75da82f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'trained_model' is not defined"]}]}]}